{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 크롤링을 위한 기초 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 엑셀화를 위한 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_sheet = excel_file.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find, find_all로 찾기\n",
    "- Q-1) #section_body > ul.type06_headline > li > dl > dt > a\n",
    "- Q-1) 위 태그에서 a를 뽑아야 한다. find -> find_all을 통해서 상세하게 추출해야만 한다.\n",
    "- Q-1) 그렇다면 위에서 find함수를 선언할 태그는? ul일까 section일까\n",
    "-  \n",
    "- Q-2) find함수에서 id를 쓰려면? \n",
    "- A-2) id = ''으로 사용하라고 했는데 아닌 것 같다\n",
    "-  \n",
    "- Q-3) find, find_all함수의 변수 타입은?\n",
    "- A-3) find는 bs4.element.Tag이며 find_all은 bs4.element.ResultSet이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select로 찾기\n",
    "- New) 다른 사이트를 뽑아보자. 무엇이 잘못된 것인지 파악해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(1,6):\n",
    "    res = requests.get(\"https://www.clien.net/service/board/park?&od=T31&po=\"+ str(index),headers=headers)\n",
    "    soup = BeautifulSoup(res.content,\"html.parser\")\n",
    "    \n",
    "    #data = soup.find('div',id='section_body')\n",
    "    #alldData = data.find_all('ul','type06_headline')\n",
    "    allData = soup.select('#div_content > div.list_content > div > div.list_title > a.list_subject > span')\n",
    "    for item in allData : \n",
    "        excel_sheet.append([item.get_text()])\n",
    "excel_file.save('New.xlsx')\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url 1페이지 형태 : https://www.clien.net/service/board/park?&od=T31&po=1\n",
    "# 1~6페이지까지\n",
    "for index in range(1,6): \n",
    "    res = requests.get(\"https://www.clien.net/service/board/park?&od=T31&po=\"+ str(index),headers=headers)\n",
    "    soup = BeautifulSoup(res.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정말 봄이 온 것인가 보네요\n",
      "일본 극우 교육 시키시는 신숙욱 씨 영상 두번째\n",
      "박범계 장관님 : 기운 차려요!\n",
      "진짜 학폭에 이어서 가지가지하네요\n",
      "소프트웨어 업데이트, 폭스바겐 vs. 테슬라\n",
      "편의점 알바 무전취식 적발한 점장.jpg\n",
      "드라마 '괴물' 몰입갑 좋네요\n",
      "오늘자 mbc 뉴스에 나온 화이자, 모더나 백신 부작용 통계.JPG\n",
      "님폰없. 이거 역대급으로 웃긴 유행어 될수있었을지도요\n",
      "1주에 10번보는 영상\n",
      "차이카드 두분 초대해드립니다\n",
      "이것이 바로 화염제모\n",
      "한쪽 귀가 없는 여성이 마스크를 하는법\n",
      "전동 드라이버를 샀는데 너무좋네요\n",
      "팬이라며!!!\n",
      "형을 위해 결단을 내린 동생.gif\n",
      "주식하는 친구 위로하기도 힘드네요\n",
      "연예인 브이로그 댓글 갑분싸.jpg\n",
      "합니다. 나눔. 하우스. 클럽. 2장.\n",
      "우리나라에 침대밑 귀신이 없는 이유~\n",
      "침착맨 염따편 2부 나왔네요ㅋㅋㅋㅋ\n",
      "역시나 중국에서 백신도 가짜가 나왔네요\n",
      "일본 국회 질의할때요...\n",
      "저는 디아2 리마스터 납득이 안가는건 아닌데\n",
      "아이폰12프맥 야간모드 10초\n",
      "아기 여대생.manhwa\n",
      "[집사법위반]현장에서 잡혀 끌려가는\n",
      "2021년 병사 월급 + 연봉.jpg\n",
      "마트 캐셔아주머니가 미성년자냐고 확인하셨습니다.\n",
      "중세 무기술을 겨루는 대회에 대해 아시나요.\n"
     ]
    }
   ],
   "source": [
    "# 1페이지 게시글 select : #div_content > div.list_content > div:nth-child(1) > div.list_title > a.list_subject > span\n",
    "allData = soup.select('#div_content > div.list_content > div > div.list_title > a.list_subject > span')\n",
    "for item in allData : \n",
    "    print(item.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OKKY 사이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(1,40): \n",
    "    res = requests.get(\"https://okky.kr/articles/tech?offset=\"+ str(index)+\"&max=20&sort=id&order=desc\",headers=headers)\n",
    "    soup = BeautifulSoup(res.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list-article > div.okkys-choice > div > ul > li:nth-child(1) > div.list-title-wrapper.clearfix > h5 > a\n",
    "allData = soup.select('#div_content > div.list_content > div > div.list_title > a.list_subject > span')\n",
    "for item in allData : \n",
    "    print(item.get_text().strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
